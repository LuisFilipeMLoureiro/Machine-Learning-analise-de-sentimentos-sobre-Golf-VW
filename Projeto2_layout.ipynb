{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome:Luís Filipe Loureiro\n",
    "\n",
    "Nome: João Bueno\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento do modelo Golf da Volkswagen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O presente estudo tem como objetivo criar um machine learning que, por meio do Teorema probabilístico de Bayes, consegue classificar um tweet quanto a sua relevância. O foco de estudo foi o carro Golf da marca Volkswagen, tentou-se criar um modelo que identifica aquelas mensagens que revelam a visão dos consumidores sobre o produto, seja no sentido de criticá-lo, seja no sentido de manifestar um desejo de adquiri-lo ou vendê-lo.\n",
    "\n",
    "Para isso foi importado 750 tweets por meio de uma conta developer no Twitter e analisado um por um quanto ao sua relevância. O critério de exploração foi o seguinte: o tweet recebeu valor 0, ou seja, irrelevante, quando se referia ao esport golf; recebeu o valor 1, ou seja, neutro aquele relacionado ao carro, mas que não exprimia qualquer juízo de valor e recebeu o valor 2, ou seja, relevante aquele que expunha uma visão do mercado sobre o produto. Para deixar mais claro o critério de avaliação, apresenta-se exemplos de tweets avaliados:\n",
    "    - \"Queria jogar golf\", classificado como irrelevante [0]\n",
    "    - \"Trouxe o golf lá da casa do Victor\", classificado como neutro [1]\n",
    "    - \"Estou apaixonada pelo golf que vão lançar\", classificado como relevante [2]\n",
    "    \n",
    "Dos 750 tweets importados, 500 foram utilizados para identificação de um padrão por meio do Teorema de Bayes e nos 250 restantes foi aplicado o machine learning e comparado os resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "# !pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: @luisfloureiro1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @luisfloureiro1\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coleta de tweets e os salvando em um arquivo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Golf'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 1600\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 500\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(list(set(msgs)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(list(set(msgs))[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(list(set(msgs))[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Filtrando as pontuação e espaços duplos dos tweets coletados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para não ser mais necessário conectar-se ao twitter, basta rodas essa cédula e a cédula que importa as bibliotecas\n",
    "tweets= pd.read_excel('Golf.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores=[]\n",
    "\n",
    "for valor in tweets.loc[:,\"Relevancia\"]:\n",
    "    valores.append(valor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;/@]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_treinamento=[]\n",
    "for tweet in tweets.loc[:,\"Treinamento\"]:\n",
    "    clean_treinamento.append((cleanup(tweet)))\n",
    "\n",
    "    \n",
    "        \n",
    "# clean_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean =pd.DataFrame(clean_treinamento)\n",
    "tweets_clean.loc[:,\"Relevancia\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando a coluna relevancia\n",
    "for numero in np.arange(0,500):\n",
    "    tweets_clean.loc[numero,\"Relevancia\"]=valores[numero]\n",
    "\n",
    "tweets_clean.columns=[\"tweet\",\"Relevancia\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando double spaces\n",
    "for numero in np.arange(0,500):\n",
    "    tweets_clean.loc[numero,\"tweet\"]=re.sub(' +', ' ',tweets_clean.loc[numero,\"tweet\"])\n",
    "    tweets_clean.loc[numero,\"tweet\"]=tweets_clean.loc[numero,\"tweet\"].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrumando base de dados Treinamento para inserir no Teorema de Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevantes=tweets_clean.loc[tweets_clean.Relevancia==0]\n",
    "\n",
    "neutros=tweets_clean.loc[tweets_clean.Relevancia==1]\n",
    "\n",
    "relevantes=tweets_clean.loc[tweets_clean.Relevancia==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=[]\n",
    "for neutro in neutros.tweet:\n",
    "    N.append(neutro)\n",
    "\n",
    "N01=','.join(N)\n",
    "serie_neutro=pd.Series(N01.split())\n",
    "tabela_neutro=serie_neutro.value_counts()\n",
    "tabela_neutro_relativa = serie_neutro.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4988"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I=[]\n",
    "for irrelevante in irrelevantes.tweet:\n",
    "    I.append(irrelevante)\n",
    "    \n",
    "I01=','.join(I)\n",
    "serie_irrelevante=pd.Series(I01.split())\n",
    "tabela_irrelevante=serie_irrelevante.value_counts()\n",
    "tabela_irrelevante_relativa = serie_irrelevante.value_counts(True)\n",
    "\n",
    "tabela_irrelevante.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=[]\n",
    "for relevante in relevantes.tweet:\n",
    "    R.append(relevante)\n",
    "    \n",
    "R01=','.join(R)\n",
    "serie_relevante=pd.Series(R01.split())\n",
    "tabela_relevante=serie_relevante.value_counts()\n",
    "tabela_relevante_relativa = serie_relevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=N01+I01+R01\n",
    "total2=len(tabela_neutro)+len(tabela_irrelevante)+len(tabela_relevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_Total=pd.Series(total.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_Total_relativa = serie_Total.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_neutro= set(tabela_neutro_relativa.index)\n",
    "set_irrelevante= set(tabela_irrelevante_relativa.index)\n",
    "set_relevante= set(tabela_relevante_relativa.index)\n",
    "int = set_neutro.intersection(set_irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter=set_relevante.intersection(int)\n",
    "#inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrumando a base de dados Teste para ser inserida no Teorema de Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('Golf.xlsx')\n",
    "teste = pd.read_excel(xls, 'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_teste=[]\n",
    "classificacao=[]\n",
    "\n",
    "for valor in teste.loc[:,\"Relevancia\"]:\n",
    "    classificacao.append(valor)\n",
    "\n",
    "for tweet in teste.loc[:,\"Teste\"]:\n",
    "    clean_teste.append((cleanup(tweet)))\n",
    "\n",
    "teste_clean=pd.DataFrame(clean_teste)\n",
    "teste_clean.loc[:,\"Relevancia\"]=1\n",
    "for numero in np.arange(0,250):\n",
    "    teste_clean.loc[numero,\"Relevancia\"]=classificacao[numero]\n",
    "\n",
    "teste_clean.columns=[\"tweet\",\"Relevancia\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numero in np.arange(0,250):\n",
    "    tweets_clean.loc[numero,\"tweet\"]=re.sub(' +', ' ',tweets_clean.loc[numero,\"tweet\"])\n",
    "    tweets_clean.loc[numero,\"tweet\"]=tweets_clean.loc[numero,\"tweet\"].strip()\n",
    "\n",
    "a =pd.Series(teste_clean.loc[:,\"tweet\"].str.split())\n",
    "lista1=[]\n",
    "for elemento in a:\n",
    "    for e in elemento:\n",
    "        lista1.append(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevante\n",
      "Irrelevante 2.8262535777821616e-07\n",
      "neutro 7.493520474786504e-08\n",
      "relevante 9.486646600585076e-07\n"
     ]
    }
   ],
   "source": [
    "frase='golf quero um'\n",
    "frase1=frase.lower()\n",
    "frase2=cleanup(frase1.lower())\n",
    "frase3=pd.Series(frase2.split())\n",
    "lista_frase=list(frase3)\n",
    "\n",
    "irrelevante=1\n",
    "neutro=1\n",
    "relevante=1\n",
    "\n",
    "P_I=(len(I)/total2)\n",
    "P_N=(len(N)/total2)\n",
    "P_R=(len(R)/total2)\n",
    "\n",
    "for word in lista_frase:\n",
    "    \n",
    "    if word not in tabela_irrelevante:\n",
    "        irrelevante*=1/((total2+len(tabela_irrelevante)))\n",
    "        \n",
    "    else:\n",
    "        irrelevante*=(tabela_irrelevante[word]+1)/(total2+len(tabela_irrelevante))\n",
    "    \n",
    "    if word not in tabela_neutro:\n",
    "        neutro*=1/((total2+len(tabela_neutro)))\n",
    "    else:\n",
    "        neutro*=(tabela_neutro[word]+1)/(total2+len(tabela_neutro))\n",
    "        \n",
    "    if word not in tabela_relevante:\n",
    "        relevante*=1/((total2+len(tabela_relevante)))\n",
    "    else:\n",
    "        relevante*=(tabela_relevante[word]+1)/(total2+len(tabela_relevante))\n",
    "        \n",
    "        \n",
    "\n",
    "irrelevante*P_I\n",
    "neutro*P_N\n",
    "relevante*P_R\n",
    "if irrelevante>neutro and irrelevante>relevante:\n",
    "    print('Neutro') \n",
    "elif relevante>irrelevante and relevante>neutro:\n",
    "    print('Relevante')\n",
    "elif neutro>irrelevante and neutro>relevante:\n",
    "    print('Irrelevante') \n",
    "    \n",
    "print(\"Irrelevante {0}\".format(irrelevante))\n",
    "print(\"neutro {0}\".format(neutro))\n",
    "print(\"relevante {0}\".format(relevante))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['golf', 'chegou', 'yaaaaaaaaah']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>um mano acabou de espetar o seu golf no muro k...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eu amo o golf ♡ https   t co ugqfnhyznh</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>esmuellert_  david_alaba ainda bem que não fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caramba tequion e os dramas q vc me prometeu m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bazert eu vou jogar golf</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  Relevancia  Teste\n",
       "0  um mano acabou de espetar o seu golf no muro k...           1      1\n",
       "1            eu amo o golf ♡ https   t co ugqfnhyznh           2      1\n",
       "2   esmuellert_  david_alaba ainda bem que não fa...           0      1\n",
       "3  caramba tequion e os dramas q vc me prometeu m...           0      1\n",
       "4                          bazert eu vou jogar golf            0      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_clean.loc[:,\"Teste\"]=1\n",
    "teste_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    um mano acabou de espetar o seu golf no muro k...\n",
       "1              eu amo o golf ♡ https   t co ugqfnhyznh\n",
       "2     esmuellert_  david_alaba ainda bem que não fa...\n",
       "3    caramba tequion e os dramas q vc me prometeu m...\n",
       "4                            bazert eu vou jogar golf \n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_clean.loc[:,\"tweet\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste=[]\n",
    "\n",
    "\n",
    "for frase in teste_clean.loc[:,\"tweet\"]:    \n",
    "    frase1=frase.lower()\n",
    "    frase3=pd.Series(frase1.split())\n",
    "    lista_frase=list(frase3)\n",
    "    irrelevante=1\n",
    "    neutro=1\n",
    "    relevante=1\n",
    "\n",
    "    for word in lista_frase:\n",
    "\n",
    "\n",
    "        if word not in tabela_irrelevante:\n",
    "            irrelevante*=1/((total2+len(tabela_irrelevante)))\n",
    "\n",
    "        else:\n",
    "            irrelevante*=(tabela_irrelevante[word]+1)/(total2+len(tabela_irrelevante))\n",
    "\n",
    "        if word not in tabela_neutro:\n",
    "            neutro*=1/((total2+len(tabela_neutro)))\n",
    "        else:\n",
    "            neutro*=(tabela_neutro[word]+1)/(total2+len(tabela_neutro))\n",
    "\n",
    "        if word not in tabela_relevante:\n",
    "            relevante*=1/((total2+len(tabela_relevante)))\n",
    "        else:\n",
    "            relevante*=(tabela_relevante[word]+1)/(total2+len(tabela_relevante))\n",
    "\n",
    "    P_I=(len(I)/total2)\n",
    "    P_N=(len(N)/total2)\n",
    "    P_R=(len(R)/total2)\n",
    "    irrelevante*P_I\n",
    "    neutro*P_N\n",
    "    relevante*P_R\n",
    "    \n",
    "    if irrelevante>neutro and irrelevante>relevante:\n",
    "        teste.append(0)\n",
    "        \n",
    "    elif relevante>irrelevante and relevante>neutro:\n",
    "        teste.append(1)\n",
    "    elif neutro>irrelevante and neutro>relevante:\n",
    "        teste.append(2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numero in np.arange(1,250):\n",
    "    teste_clean.loc[numero,\"Teste\"]=teste[numero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>um mano acabou de espetar o seu golf no muro k...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eu amo o golf ♡ https   t co ugqfnhyznh</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>esmuellert_  david_alaba ainda bem que não fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caramba tequion e os dramas q vc me prometeu m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bazert eu vou jogar golf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  Relevancia  Teste\n",
       "0  um mano acabou de espetar o seu golf no muro k...           1      1\n",
       "1            eu amo o golf ♡ https   t co ugqfnhyznh           2      0\n",
       "2   esmuellert_  david_alaba ainda bem que não fa...           0      0\n",
       "3  caramba tequion e os dramas q vc me prometeu m...           0      0\n",
       "4                          bazert eu vou jogar golf            0      0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Teste</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Teste         0   1  2\n",
       "Relevancia            \n",
       "0           136   9  6\n",
       "1            35  13  6\n",
       "2            25  21  0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = pd.crosstab(teste_clean.Relevancia, teste_clean.Teste)\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.596\n"
     ]
    }
   ],
   "source": [
    "a=136+13\n",
    "print(a/250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
